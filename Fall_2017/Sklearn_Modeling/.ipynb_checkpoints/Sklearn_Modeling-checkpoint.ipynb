{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling Data and Comparing Predictions with Sklearn\n",
    "\n",
    "Sci-kit Learn, or **Sklearn** for short, is one of the quintessential scientific computing modules for Python. Primarily known as an out-of-the-box machine learning tool, sklearn is able to quickly train and test multiple models. In this tutorial, we will give an overview of only the very basics of sklearn, as this module has immense capabilities. Using a dataset pertaining to car ratings, we will compare six different machine learning models to see which perform best. In doing so, we will also see how to train and test six common machine learning methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Few Notes\n",
    "\n",
    "Usually, DPUDS ML tutorials **emphasize the methodology behind the models**, or how different machine learning algorithms actually work. This tutorial will be an **exception to this rule**. Due to the fact that sklearn is incredibly user friendly, it is (fortunately, or unfortunately) **possible for someone to train and test a model that they do not understand**. While we certainly recommend that people **learn the methods behind the madness** of sklearn and ML in general, we also realize that many people have limited time and want to experiment with pre-configured code. If you want to hit the ground running at a dead sprint, then this tutorial will assist you. With that said, it is crucial that people more serious about ML eventually learn how each model works, and why."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Import Dependencies\n",
    "\n",
    "Since we typically build our models from scratch, this section will be much larger than the others. Below you will see standard modules imported (numpy, pandas, ...), as well as matplotlib and six sklearn modules. Matplotlib will be used to visualize our results, and sklearn modules will import the models themselves.\n",
    "\n",
    "**Standard Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Standard imports\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd \n",
    "import os\n",
    "from matplotlib import style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sklearn Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# K-Nearest Neighbors\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Random Forest Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Support Vector Machine model\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Stochastic Gradient Descent Optimizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "# Gaussian Naive Bayes Optimizer\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the exception of **train_test_split**, the models above are imported as objects that can be customized in many ways. We will see some of this customization below, but for additional insight you can find the **documentation for these models here**:\n",
    "\n",
    "- [K-Neighbors Classifier](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)\n",
    "- [Random Forest Classifier](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)\n",
    "- [Support Vector Machine](http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html)\n",
    "- [Logistic Regression](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)\n",
    "- [Stochastic Gradient Descent (SGDC)](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html)\n",
    "- [Gaussian Naive Bayes Classifier](http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, lets locate out dataset in our directory and change matplotlib to include a customized style. Both of these will be very import down the road."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Style that will be used for the graph that shows model comparison\n",
    "style.use('ggplot')\n",
    "\n",
    "#Change this to the working directory of your dataset\n",
    "os.chdir('/Users/Sam/Documents/Python/DPUDS/DPUDS_Meetings/Fall_2017/Sklearn_Modeling')\n",
    "\n",
    "#Dictionary to translate numbers into user friendly strings for overall car rating\n",
    "target_dict = {1:'Unacceptable',2:'Acceptable',3:'Good',4:'Very_Good'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Import and Refine Dataset\n",
    "\n",
    "Now we are ready to import our data. This dataset captures several features of a car, as outlined below by the host of the dataset, the **University of California at Irvine**. Ultimately, the goal is to predict the overall rating a car recieves from its features. The features and other information are included below."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "INFORMATION ABOUT DATASET: Classifying Overall Rating Cars Get Based On Attributes\n",
    "\n",
    "1. Title: Car Evaluation Database\n",
    "\n",
    "2. Sources:\n",
    "   (a) Creator: Marko Bohanec\n",
    "   (b) Donors: Marko Bohanec   (marko.bohanec@ijs.si)\n",
    "               Blaz Zupan      (blaz.zupan@ijs.si)\n",
    "   (c) Date: June, 1997\n",
    "\n",
    "3. Past Usage:\n",
    "\n",
    "   The hierarchical decision model, from which this dataset is\n",
    "   derived, was first presented in \n",
    "\n",
    "   M. Bohanec and V. Rajkovic: Knowledge acquisition and explanation for\n",
    "   multi-attribute decision making. In 8th Intl Workshop on Expert\n",
    "   Systems and their Applications, Avignon, France. pages 59-78, 1988.\n",
    "\n",
    "   Within machine-learning, this dataset was used for the evaluation\n",
    "   of HINT (Hierarchy INduction Tool), which was proved to be able to\n",
    "   completely reconstruct the original hierarchical model. This,\n",
    "   together with a comparison with C4.5, is presented in\n",
    "\n",
    "   B. Zupan, M. Bohanec, I. Bratko, J. Demsar: Machine learning by\n",
    "   function decomposition. ICML-97, Nashville, TN. 1997 (to appear)\n",
    "\n",
    "4. Relevant Information Paragraph:\n",
    "\n",
    "   Car Evaluation Database was derived from a simple hierarchical\n",
    "   decision model originally developed for the demonstration of DEX\n",
    "   (M. Bohanec, V. Rajkovic: Expert system for decision\n",
    "   making. Sistemica 1(1), pp. 145-157, 1990.). The model evaluates\n",
    "   cars according to the following concept structure:\n",
    "\n",
    "   CAR                      car acceptability\n",
    "   . PRICE                  overall price\n",
    "   . . buying               buying price\n",
    "   . . maint                price of the maintenance\n",
    "   . TECH                   technical characteristics\n",
    "   . . COMFORT              comfort\n",
    "   . . . doors              number of doors\n",
    "   . . . persons            capacity in terms of persons to carry\n",
    "   . . . lug_boot           the size of luggage boot\n",
    "   . . safety               estimated safety of the car\n",
    "   \n",
    "5. Number of Instances: 1728\n",
    "   (instances completely cover the attribute space)\n",
    "\n",
    "6. Number of Attributes: 6\n",
    "\n",
    "7. Attribute Values:\n",
    "\n",
    "   buying       v-high, high, med, low\n",
    "   maint        v-high, high, med, low\n",
    "   doors        2, 3, 4, 5-more\n",
    "   persons      2, 4, more\n",
    "   lug_boot     small, med, big\n",
    "   safety       low, med, high\n",
    "\n",
    "8. Missing Attribute Values: none\n",
    "\n",
    "9. Class Distribution (number of instances per class)\n",
    "\n",
    "   class      N          N[%]\n",
    "   -----------------------------\n",
    "   unacc     1210     (70.023 %) \n",
    "   acc        384     (22.222 %) \n",
    "   good        69     ( 3.993 %) \n",
    "   v-good      65     ( 3.762 %) \n",
    "\n",
    "** We will predict the estimated rating of a car (low, med, high, v-high) using the data shown and compare it \n",
    "** across different models with sklearn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import Data**\n",
    "\n",
    "Ok, now that we know more about our dataset, let's import it and write a function to **replace all string values with dummy variables**. Fortunately for us, this dataset has **no missing or corrupted data**, so we will not have to worry about that. As seen below, our dataset looks like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  buy_price maintanence_price num_people num_doors trunk_size safety_rating  \\\n",
      "0     vhigh             vhigh          2         2      small           low   \n",
      "1     vhigh             vhigh          2         2      small           med   \n",
      "2     vhigh             vhigh          2         2      small          high   \n",
      "3     vhigh             vhigh          2         2        med           low   \n",
      "4     vhigh             vhigh          2         2        med           med   \n",
      "\n",
      "  overall_rating  \n",
      "0          unacc  \n",
      "1          unacc  \n",
      "2          unacc  \n",
      "3          unacc  \n",
      "4          unacc  \n"
     ]
    }
   ],
   "source": [
    "#Import data using pandas\n",
    "data = pd.read_csv('Car_Ratings.csv', names = [    'buy_price', \n",
    "                                                   'maintanence_price',\n",
    "                                                   'num_people',\n",
    "                                                   'num_doors',\n",
    "                                                   'trunk_size',\n",
    "                                                   'safety_rating',\n",
    "                                                   'overall_rating'])\n",
    "\n",
    "#Take a look at our data\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Refine and Convert Data**\n",
    "\n",
    "Perfect! All siz fields are present as under the correct column header. However, we cannot do predictive analysis on data that exists as strings (or, at least, it becomes much more difficult). Therefore, we will convert all string values into dummy variables. For example, the values of **`buy_price`** **(low, med, high, vhigh)** will be replaced by **(1,2,3,4)**. We will do this for all data that is not numeric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   buy_price  maintanence_price  num_people  num_doors  trunk_size  \\\n",
      "0          4                  4           2          2           1   \n",
      "1          4                  4           2          2           1   \n",
      "2          4                  4           2          2           1   \n",
      "3          4                  4           2          2           2   \n",
      "4          4                  4           2          2           2   \n",
      "\n",
      "   safety_rating  \n",
      "0              1  \n",
      "1              2  \n",
      "2              3  \n",
      "3              1  \n",
      "4              2  \n",
      "\n",
      "Class Labels\n",
      "0    1\n",
      "1    1\n",
      "2    1\n",
      "3    1\n",
      "4    1\n",
      "Name: overall_rating, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "###########################################\n",
    "#\n",
    "# Data Refinement and Dummy Variables\n",
    "#\n",
    "###########################################\n",
    "\n",
    "#Refines our data in place\n",
    "def refine_data_master(data):\n",
    "    # Buy price\n",
    "    data.replace({'buy_price':{'vhigh':4,'high':3,'med':2,'low':1}}, regex = True, inplace = True)\n",
    "    # Maintanence Price\n",
    "    data.replace({'maintanence_price':{'vhigh':4,'high':3,'med':2,'low':1}}, regex = True, inplace = True)\n",
    "    # Number of doors\n",
    "    data.replace({'num_doors':{'2':2,'4':4,'more':6}}, regex = True, inplace = True)\n",
    "    # Number of people\n",
    "    data.replace({'num_people':{'2':2,'3':3,'4':4,'5more':5}}, regex = True, inplace = True)\n",
    "    # Trunk Size\n",
    "    data.replace({'trunk_size':{'small':1,'med':2,'big':3}}, regex = True, inplace = True)\n",
    "    # Safety rating\n",
    "    data.replace({'safety_rating':{'low':1,'med':2,'high':3}}, regex = True, inplace = True)\n",
    "\n",
    "    # Overall rating (our labels) (MAKE SURE unacc goes before acc, and vgood before good)\n",
    "    data.replace({'overall_rating':{'vgood':4,'good':3,'unacc':1,'acc':2}}, regex = True, inplace = True)\n",
    "\n",
    "    # Data without labels\n",
    "    data_features = data.drop('overall_rating',axis = 1)\n",
    "\n",
    "    # Data labels only\n",
    "    data_labels = data.overall_rating\n",
    "    \n",
    "    # Returns data and labels\n",
    "    return data_features, data_labels\n",
    "\n",
    "data_features, data_labels = refine_data_master(data)\n",
    "\n",
    "#Print features\n",
    "print(data_features.head())\n",
    "\n",
    "\n",
    "\n",
    "#Print labels\n",
    "print()\n",
    "print(\"Class Labels\")\n",
    "print(data_labels.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see here, we have replaced the string values of the dataset with dummy variable numbers, and split the data into **features, things that describe the data** and **labels, things we are trying to predict**. Now we are ready to start creating an algorithm to run these models and compare them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Verify Data Can be Used to Train a Single Model\n",
    "\n",
    "This this tutorial may be a little more programmatically intensive than previous ones, we are going to first **verify a proof concept**. Basically, we want to be sure that this data will actually be suitable to run a model. In order to be sure of this, we will train and test a **K-Nearest Neighbors** model with sklearn and visualize it in the same way we have in previous tutorials. But first, we need a way to split the training and testing data with sklearn.\n",
    "\n",
    "**Split Data into Train and Test Samples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data_features, data_labels, test_size = 0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that is it. The only thing you have to do to get training and testing datasets in sklearn is **call the train_test_split function**. **`X_train`** and **`y_train`** are the training data features and labels, respectively, where as the **`_test`** variables are their testing counterparts. The size of the testing sample is **25% of the entire dataset**. With this data now available, we can **create our KNN model**.\n",
    "\n",
    "**Create KNN Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "This is the sklearn KNN model. By passing in the train and test\n",
    "data, we can train the model and then test it. This function\n",
    "does exactly that and then returns the accuracy, as found\n",
    "with the function iter_accuracy\n",
    "'''\n",
    "def KNN_train_test_model(X_train, X_test, y_train, y_test):\n",
    "    KNN_clf = KNeighborsClassifier(n_neighbors = 5, \n",
    "                                   weights = 'uniform', \n",
    "                                   algorithm = 'auto', \n",
    "                                   leaf_size = 30)\n",
    "    KNN_clf.fit(X_train,y_train)\n",
    "    predicted = list(KNN_clf.predict(X_test))\n",
    "    actual = list(y_test)\n",
    "\n",
    "    #accuracy = iter_accuracy(actual,predicted)\n",
    "\n",
    "    return actual, predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's break down the function above. The inputs needed are four datasets, **training features and labels, and testing features and labels**. With sklearn, first you need to **initialize your classifier**, with is done in the first line of code and assigned to the variable **`KNN_clf`**. \n",
    "\n",
    "Next, to **train the data**, you call the **`.fit()`** method, which will train the data instanstly and store the trained model in your classifier object (which is called **`KNN_clf`** above). \n",
    "\n",
    "Finally, to **get a list of predicted classes** for the testing dataset, you can call **`.predict()`** on the testing data features. Ignore the commented out function for accuracy for now; it will be uncommented and used later.\n",
    "\n",
    "The function outputs the actual ratings of the cars and the predicted ratings of the cars as lists."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualize our results**\n",
    "\n",
    "Now that we have a model we can run, let's verify its accuracy with the functions we have used in previous tutorials. These are shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "This function is equivalent to what we saw in the KNN\n",
    "tutorial. It shows the accuracy of the model, including\n",
    "the number correct and the number incorrect. Its inputs\n",
    "are the actual list of labels and the list of predicted\n",
    "labels.\n",
    "'''\n",
    "def viz_get_accuracy(actual, predicted):\n",
    "    count = 0\n",
    "    for i in range(len(actual)):\n",
    "        if actual[i] == predicted[i]:\n",
    "            count += 1\n",
    "    num_correct = count\n",
    "    num_incorrect = len(actual) - count\n",
    "    return \"Accuracy: \" + str(count / len(actual)*100) + \" percent\" + '\\n' + \"Number correct: \" + str(num_correct) + '\\n' + \"Number incorrect: \" + str(num_incorrect)\n",
    "\n",
    "\n",
    "'''\n",
    "Inputs are actual and predicted labels for the dataset. \n",
    "This model prints the results of the model next to the actual\n",
    "results for side-by-side viewing.\n",
    "'''\n",
    "def viz_view_results(actual,predicted):\n",
    "    result = pd.DataFrame()\n",
    "    for i in range(len(actual)):\n",
    "        actual[i] = target_dict[actual[i]]\n",
    "        predicted[i] = target_dict[predicted[i]]\n",
    "    result['ACTUAL'] = actual\n",
    "    result['PREDICTED'] = predicted\n",
    "    result['CORRECT?'] = [actual[i] == predicted[i] for i in range(len(actual))]\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to see if our model is working as expected, and if our data is compatible with sklearn. This is a **particularly important** step as it will **tell us if we have bad data, data conversions, or incompatible features**. Let's take a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           ACTUAL     PREDICTED CORRECT?\n",
      "0            Good    Acceptable    False\n",
      "1      Acceptable    Acceptable     True\n",
      "2      Acceptable    Acceptable     True\n",
      "3    Unacceptable  Unacceptable     True\n",
      "4      Acceptable    Acceptable     True\n",
      "5    Unacceptable  Unacceptable     True\n",
      "6    Unacceptable  Unacceptable     True\n",
      "7    Unacceptable  Unacceptable     True\n",
      "8      Acceptable    Acceptable     True\n",
      "9    Unacceptable  Unacceptable     True\n",
      "10     Acceptable  Unacceptable    False\n",
      "11   Unacceptable  Unacceptable     True\n",
      "12           Good          Good     True\n",
      "13     Acceptable    Acceptable     True\n",
      "14     Acceptable    Acceptable     True\n",
      "15   Unacceptable  Unacceptable     True\n",
      "16   Unacceptable  Unacceptable     True\n",
      "17     Acceptable    Acceptable     True\n",
      "18           Good          Good     True\n",
      "19      Very_Good     Very_Good     True\n",
      "20   Unacceptable  Unacceptable     True\n",
      "21   Unacceptable  Unacceptable     True\n",
      "22           Good    Acceptable    False\n",
      "23   Unacceptable  Unacceptable     True\n",
      "24   Unacceptable  Unacceptable     True\n",
      "25   Unacceptable  Unacceptable     True\n",
      "26      Very_Good     Very_Good     True\n",
      "27   Unacceptable  Unacceptable     True\n",
      "28   Unacceptable  Unacceptable     True\n",
      "29     Acceptable     Very_Good    False\n",
      "..            ...           ...      ...\n",
      "402  Unacceptable  Unacceptable     True\n",
      "403    Acceptable    Acceptable     True\n",
      "404  Unacceptable  Unacceptable     True\n",
      "405  Unacceptable  Unacceptable     True\n",
      "406  Unacceptable  Unacceptable     True\n",
      "407  Unacceptable  Unacceptable     True\n",
      "408  Unacceptable  Unacceptable     True\n",
      "409  Unacceptable  Unacceptable     True\n",
      "410  Unacceptable  Unacceptable     True\n",
      "411  Unacceptable  Unacceptable     True\n",
      "412  Unacceptable  Unacceptable     True\n",
      "413    Acceptable    Acceptable     True\n",
      "414  Unacceptable  Unacceptable     True\n",
      "415  Unacceptable  Unacceptable     True\n",
      "416  Unacceptable  Unacceptable     True\n",
      "417          Good          Good     True\n",
      "418  Unacceptable  Unacceptable     True\n",
      "419  Unacceptable    Acceptable    False\n",
      "420  Unacceptable  Unacceptable     True\n",
      "421    Acceptable  Unacceptable    False\n",
      "422    Acceptable    Acceptable     True\n",
      "423  Unacceptable  Unacceptable     True\n",
      "424  Unacceptable  Unacceptable     True\n",
      "425  Unacceptable  Unacceptable     True\n",
      "426  Unacceptable  Unacceptable     True\n",
      "427    Acceptable    Acceptable     True\n",
      "428    Acceptable    Acceptable     True\n",
      "429    Acceptable  Unacceptable    False\n",
      "430    Acceptable    Acceptable     True\n",
      "431  Unacceptable  Unacceptable     True\n",
      "\n",
      "[432 rows x 3 columns]\n",
      "\n",
      "Accuracy: 93.05555555555556 percent\n",
      "Number correct: 402\n",
      "Number incorrect: 30\n"
     ]
    }
   ],
   "source": [
    "#Training and testing model; getting actual and predicted classes\n",
    "actual, predicted = KNN_train_test_model(X_train, X_test, y_train, y_test)\n",
    "\n",
    "# Dataframe of the results\n",
    "results = viz_view_results(actual,predicted)\n",
    "\n",
    "# Messages about accuracy\n",
    "accuracy = viz_get_accuracy(actual, predicted)\n",
    "\n",
    "print(results)\n",
    "print()\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not bad, not bad at all. It looks like we have **proved that we can implement a training and testing function for sklearn's KNN classifier** for finding the overall rating a car has, and that the data is **predicting fairly efficiently**. Now let's take things up a notch and **create a classification comparison engine**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Create Six Sklearn Models\n",
    "\n",
    "We have taken a deep dive into how to train and test an sklearn model. Now, let's train and test a bunch of them and pit them against each other. First, let's decide on how to compare the efficiency of each model. The immediate thought that comes to mind is **accuracy**. So, let's create a function that will just return the accuracy of a given model.\n",
    "\n",
    "**Create Accuracy Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "This model iteratively returns a single value,\n",
    "the accuracy of the model as found by \n",
    "num_correct/tot_num_samples. This is the function\n",
    "that will be called iteratively when the sampling\n",
    "engine runs for all sklearn models. Inputs are \n",
    "actual labels, and predicted labels.\n",
    "'''\n",
    "def iter_accuracy(actual, predicted):\n",
    "    correct_count = 0\n",
    "    for i in range(len(actual)):\n",
    "        if actual[i] == predicted[i]:\n",
    "            correct_count += 1\n",
    "    accuracy = correct_count/len(actual)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple enough. You may have noticed that this function bears a striking similarity to our previous accuracy function. It is just pared down to only **return an accuracy value between 0 and 1**. Now, let's see if we can alter our KNN function to only return the accuracy of the model.\n",
    "\n",
    "**Adjust KNN Function to only Return Accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "This is the sklearn KNN model. By passing in the train and test\n",
    "data, we can train the model and then test it. This function\n",
    "does exactly that and then returns the accuracy, as found\n",
    "with the function iter_accuracy\n",
    "'''\n",
    "def KNN_train_test_model(X_train, X_test, y_train, y_test):\n",
    "    KNN_clf = KNeighborsClassifier(n_neighbors = 5, \n",
    "                                   weights = 'uniform', \n",
    "                                   algorithm = 'auto', \n",
    "                                   leaf_size = 30)\n",
    "    KNN_clf.fit(X_train,y_train)\n",
    "    predicted = list(KNN_clf.predict(X_test))\n",
    "    actual = list(y_test)\n",
    "\n",
    "    accuracy = iter_accuracy(actual,predicted)\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, this is where the iter_accuracy function that was commented out above finds its purpose. Now, if this function were run, it would **return the decimal form the accuracy of the model** (or 0.930555 in the case above). \n",
    "\n",
    "**Create Train_Test_Accuracy Functions for All Other Models**\n",
    "\n",
    "Now that we have a template function for train a model, testing it, and returning its accuracy, let's re-create it for all of the other models we imported. \n",
    "\n",
    "**NOTE:** Some of these models have additional arguments included. We **will not** have time to cover what these are or how they work. For more information **see the Python documentation cited above**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "This is the sklearn SVM model. By passing in the train and test\n",
    "data, we can train the model and then test it. This function\n",
    "does exactly that and then returns the accuracy, as found\n",
    "with the function iter_accuracy\n",
    "'''\n",
    "def SVM_train_test_model(X_train, X_test, y_train, y_test):\n",
    "    SVM_clf = SVC()\n",
    "    SVM_clf.fit(X_train,y_train)\n",
    "    predicted = list(SVM_clf.predict(X_test))\n",
    "    actual = list(y_test)\n",
    "\n",
    "    accuracy = iter_accuracy(actual,predicted)\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "'''\n",
    "This is the sklearn GNB model. By passing in the train and test\n",
    "data, we can train the model and then test it. This function\n",
    "does exactly that and then returns the accuracy, as found\n",
    "with the function iter_accuracy\n",
    "'''\n",
    "def GNB_train_test_model(X_train, X_test, y_train, y_test):\n",
    "    GNB_clf = GaussianNB()\n",
    "    GNB_clf.fit(X_train, y_train)\n",
    "    predicted = list(GNB_clf.predict(X_test))\n",
    "    actual = list(y_test)\n",
    "\n",
    "    accuracy = iter_accuracy(actual,predicted)\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "'''\n",
    "This is the sklearn Stochastic Gradient Descent model. By passing \n",
    "in the train and test data, we can train the model and then test it. \n",
    "This function does exactly that and then returns the accuracy, as \n",
    "found with the function iter_accuracy.\n",
    "'''\n",
    "def SGDC_train_test_model(X_train, X_test, y_train, y_test):\n",
    "    SGDC_clf = SGDClassifier(loss ='hinge',\n",
    "                             alpha = 0.0001,\n",
    "                             fit_intercept = True,\n",
    "                             learning_rate = 'optimal',\n",
    "                             average = False)\n",
    "    SGDC_clf.fit(X_train, y_train)\n",
    "    predicted = list(SGDC_clf.predict(X_test))\n",
    "    actual = list(y_test)\n",
    "\n",
    "    accuracy = iter_accuracy(actual,predicted)\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "'''\n",
    "This is the sklearn Random Forest model. By passing \n",
    "in the train and test data, we can train the model and then test it. \n",
    "This function does exactly that and then returns the accuracy, as \n",
    "found with the function iter_accuracy.\n",
    "'''\n",
    "def RF_train_test_model(X_train, X_test, y_train, y_test):\n",
    "    RF_clf = RandomForestClassifier(n_estimators = 10,\n",
    "                                    criterion = 'gini',\n",
    "                                    max_depth = None,\n",
    "                                    bootstrap = True)\n",
    "    RF_clf.fit(X_train, y_train)\n",
    "    predicted = list(RF_clf.predict(X_test))\n",
    "    actual = list(y_test)\n",
    "\n",
    "    accuracy = iter_accuracy(actual,predicted)\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "'''\n",
    "This is the sklearn Logistic Regression model. By passing \n",
    "in the train and test data, we can train the model and then test it. \n",
    "This function does exactly that and then returns the accuracy, as \n",
    "found with the function iter_accuracy.\n",
    "'''\n",
    "def LOG_train_test_model(X_train, X_test, y_train, y_test):\n",
    "    LOG_clf = LogisticRegression(penalty = 'l2',\n",
    "                                 fit_intercept = True,\n",
    "                                 solver = 'liblinear',\n",
    "                                 class_weight = None)\n",
    "    LOG_clf.fit(X_train, y_train)\n",
    "    predicted = list(LOG_clf.predict(X_test))\n",
    "    actual = list(y_test)\n",
    "\n",
    "    accuracy = iter_accuracy(actual,predicted)\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And there we go. All six of our models are now ready to be trained on our car ratings data. However, it would be a pain to run these one-by-one, so let's create an engine to compare this data. \n",
    "\n",
    "**NOTE on Sampling**\n",
    "\n",
    "Our goal is to compare multiple sklearn models. It is important to note that **a given model can potentially have very different accuracies, depending on the records in its training dataset**. \n",
    "\n",
    "Therefore, if we ran the same model multiple times -- re-splitting the dataset every time -- **it would give us different accuracies each time. This is why we can compare these models in the first place**. Some may be more robust, and work better across all types of training datasets, not just representative ones.\n",
    "\n",
    "We will use this concept to build our sampling engine ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Create a Sampling Engine, Visualization Function, and a Main Method\n",
    "\n",
    "So we won't have to manually run models over and over to get a list of accuracies, let's create a sampling model to do that for us. It is written below.\n",
    "\n",
    "**Create Sampling Engine**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gather_samples(models,num_samples,test_ratio,data_features,data_labels):\n",
    "    results_dict = {}\n",
    "    for model in models:\n",
    "        res_list = []\n",
    "        model_tag = model.__name__.rsplit('_')[0]\n",
    "        for j in range(num_samples):\n",
    "            X_train, X_test, y_train, y_test = train_test_split(data_features, data_labels, test_size = test_ratio)\n",
    "            accuracy = model(X_train,X_test,y_train,y_test)\n",
    "            res_list.append(accuracy)\n",
    "        results_dict[model_tag] = res_list\n",
    "\n",
    "    results_df = pd.DataFrame.from_dict(results_dict)\n",
    "\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function is the most complex, so we will walk through it slowly.\n",
    "\n",
    "First, we want to store accuracy results as a dictionary in the form **{model_name: [$acc_1$,$acc_2$...]}**\n",
    "\n",
    "**`results_dict`** is the dictionary, and **`res_list`** is the list of accuracies. The function takes inputs of different functions for each model as a list (saved as **`models`**), the number of accuracy samples we want, a test ratio for the data, and finall the data_features and data_labels.\n",
    "\n",
    "For each model included in the **`models`** list, the data is split, trained, and tested. The accuracy is found, and then added, to the res_list. Once there are enough sample in the res_list (equal to num_samples), the entire list is added to the dictionary with the Key value of the model.\n",
    "\n",
    "The key value of the model, or **`model_tag`**, is the first few capital letters before the underscore of each model name. **For example:** `KNN_train_test_model` would have a model tag of **`KNN`**. Finally the **results of the dictionary are converted into a dataframe and returned**. A sample of this can be seen below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        GNB       KNN       LOG        RF      SGDC       SVM\n",
      "0  0.671296  0.942130  0.759259  0.962963  0.740741  0.935185\n",
      "1  0.680556  0.949074  0.787037  0.956019  0.733796  0.967593\n",
      "2  0.733796  0.923611  0.803241  0.969907  0.789352  0.969907\n",
      "3  0.745370  0.921296  0.812500  0.969907  0.768519  0.939815\n",
      "4  0.747685  0.974537  0.775463  0.965278  0.766204  0.951389\n",
      "5  0.675926  0.921296  0.770833  0.958333  0.791667  0.956019\n",
      "6  0.675926  0.949074  0.759259  0.972222  0.784722  0.967593\n",
      "7  0.722222  0.937500  0.793981  0.960648  0.733796  0.956019\n",
      "8  0.722222  0.949074  0.773148  0.962963  0.756944  0.956019\n",
      "9  0.682870  0.932870  0.759259  0.960648  0.787037  0.956019\n"
     ]
    }
   ],
   "source": [
    "models = [RF_train_test_model,\n",
    "               LOG_train_test_model,\n",
    "               GNB_train_test_model,\n",
    "               KNN_train_test_model,\n",
    "               SVM_train_test_model,\n",
    "               SGDC_train_test_model]\n",
    "\n",
    "\n",
    "samples = gather_samples(models,10,0.25,data_features,data_labels)\n",
    "\n",
    "#Print the dataframe of accuracy samples\n",
    "print(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create Visualization Function**\n",
    "\n",
    "Now we have our accuracy data, let's visualize it with boxplots and matplotlib. The function will take a single input of a sample dataframe, and display boxplots of the accuracies of each model. The function can be seen below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "This function visualizes the results of the gather samples function\n",
    "above. By taking the results dataframe, it will give a graph of the boxplots \n",
    "of accuracy results, one for each model. This will be labeled by the headers \n",
    "of the dataframe.\n",
    "'''\n",
    "def visualize_results(results_df):\n",
    "    #Intialize and plot data\n",
    "    plt.figure()\n",
    "    results_df.boxplot()\n",
    "    \n",
    "    #Axes labels and title\n",
    "    plt.xlabel('Classifier Model')\n",
    "    plt.ylabel('Prediction Accuracy')\n",
    "    plt.title('Classifier Accuracy Analysis with Sklearn')\n",
    "\n",
    "    #Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create Main Method**\n",
    "\n",
    "Looks like everything is ready to go. Since we have so many moving parts, it makes sense here to create a main method, from which we can run everything at once as well as customize our parameters. It can be seen below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import data using pandas\n",
    "data = pd.read_csv('Car_Ratings.csv', names = [    'buy_price', \n",
    "                                                   'maintanence_price',\n",
    "                                                   'num_people',\n",
    "                                                   'num_doors',\n",
    "                                                   'trunk_size',\n",
    "                                                   'safety_rating',\n",
    "                                                   'overall_rating'])\n",
    "\n",
    "#Dictionary to translate numbers into user friendly strings for overall car rating\n",
    "target_dict = {1:'Unacceptable',2:'Acceptable',3:'Good',4:'Very_Good'}\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "The main method runs the model, taking in the test ratio you want, \n",
    "the number of samples you want, and the dataset, after it has been\n",
    "refined of all bad data.\n",
    "'''\n",
    "def main(data, num_samples, test_ratio):\n",
    "\n",
    "    #Split data into features and labels\n",
    "    data_features, data_labels = refine_data_master(data)\n",
    "    \n",
    "    #Create list of classifiers\n",
    "    classifiers = [RF_train_test_model,\n",
    "                   LOG_train_test_model,\n",
    "                   GNB_train_test_model,\n",
    "                   KNN_train_test_model,\n",
    "                   SVM_train_test_model,\n",
    "                   SGDC_train_test_model]\n",
    "\n",
    "    #Get a df of the accuracy results for each model\n",
    "    results_df = gather_samples(classifiers,num_samples,test_ratio,data_features,data_labels)\n",
    "\n",
    "    #Visualize the results\n",
    "    visualize_results(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the main method, you can run all of our code by simply giving it a dataset, the number of samples you want to collect from every model, and the test_ratio you want to use to split your data. In return, the method will output a graph of boxplots, one for each model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Run Main Method\n",
    "\n",
    "Finally, after all of that coding, we can see which models perform the best for this dataset. To be sure we are getting reliable results, we will **gather 100 accuracy samples from each model, and give each a 25% testing dataset**. In essence, the gather_samples function operates in the same way as a **Monte Carlo Simulation**. \n",
    "\n",
    "Here are the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEaCAYAAAAL7cBuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3XdYFNf+P/D3wtIXkY6IlWYhEYWgggIi0QSJQW8iKhYs\nMUYNlmAMCtFrSTSiRiy5BJFYE5Jo0Bg0VwQBQUFRbKDi125QpIN0dn5/+GOu6+7CgGxh/byeh+dh\nZs7MfA7L7mfnnDNneAzDMCCEEEJeoaboAAghhCgnShCEEEIkogRBCCFEIkoQhBBCJKIEQQghRCJK\nEIQQQiSiBNFGgYGB8Pb2ltv5Vq1aBRsbG5F1v/32G6ytraGuro7AwECcPn0aPB4Pjx49kltcRP7a\n+3/vp59+Ap/Pb7fjtYTr/6ks32Oenp6YPXu21O30XnqBEoQERUVF+PLLL2Fvbw9tbW2YmZnB3d0d\ne/fuRUNDg0JiCg4Oxrlz59jlxsZGzJw5ExMmTMCDBw+wdetWuLq6Ij8/H5aWljKNJSMjA+rq6njn\nnXdkep6OqF+/flBXV8f169cVHQpn/v7+ePz4sdzO9+r/6ZkzZ8Dj8XDv3r12OX5RURGCgoLQq1cv\naGlpwdTUFMOHD8fPP//cLsd/k8jva0MH8fDhQwwbNgx8Ph+rV6/GwIEDoaGhgfT0dISHh+Ptt9+G\no6Oj3OMSCAQQCATscn5+PiorK+Hj44OuXbuy6y0sLF7rPAzDoKGhARoaGlLLREZG4rPPPsPBgweR\nnZ2tkL/Hq+rq6qCpqanQGFJSUlBcXIxZs2bhxx9/xNatWxUaD1c6OjrQ0dGR2/k0NTVf+/+0Of/6\n179QWlqKyMhI2Nvbo7CwEBkZGSgqKpLZOduqvr6+2feawjFEhK+vL2Nubs6UlpaKbaurq2MqKysZ\nhmGY6dOnMyNHjmS3ZWVlMe+99x5jamrK6OnpMc7Ozszx48dF9o+Li2McHR0ZHR0dxsDAgHnnnXeY\nixcvssdevHgx07VrV0ZTU5OxsLBg/P392X1XrlzJWFtbMwzDMDExMQwAkZ+kpCQmKSmJAcA8fPiQ\n3S8vL48ZP348Y2BgwHTu3Jl59913mStXrrDbY2JiGHV1dSYxMZFxdHRkNDQ0mPj4eKl/n9LSUkZX\nV5e5cuUKM3fuXGbu3LliZSoqKpiFCxcyVlZWjKamJtOjRw9m3bp17PanT58ygYGBjJmZGaOlpcXY\n2dkx0dHRDMMwEuvAMAyjrq7OxMTEMAzDMHfv3mUAMPv372fef/99RldXl/nyyy8ZoVDIzJ49m+nd\nuzejra3N9OrViwkJCWFqampEjnXy5Elm2LBhjI6ODtOpUyfG3d2duX37NpOUlMSoqakxDx48ECm/\nZ88eplOnTuxrL01AQACzZMkS5ty5c4yhoSFTXV0tsr3pfyYyMpLp3r07o6+vz3zwwQfMkydP2DJ3\n7txhxo0bx3Tp0oXR0dFhHBwcmL1790o8TtPfi0vM69atY3r16sVoamoyJiYmzKhRo5iqqiqGYf73\nP9CkrKyMCQwMZMzNzRlNTU3GysqKWbx4sdR6T5kyhZk8eTK7vHv3bgYAExUVxa6bPHkyM3HiRDbm\npte46bV8+cfDw4Pz3+tVJSUlDADmzz//lFqGYRjGw8ODmTVrFrt86dIlpkuXLsySJUsYoVDYpvdS\ncXExExAQwHTr1o3R1tZm7OzsmPDwcEYoFLJlmuoUERHB9OjRg+HxeExVVRUbz+rVqxlzc3PG0NCQ\nmTp1KlNRUdFsPWSNmpheUlxcjPj4eCxYsAAGBgZi2zU0NKCnpydx3/Lycvj7+yMpKQkXL17E6NGj\nMXbsWNy6dQsA8OTJE3z88ceYNGkSrl+/jrNnz2LRokVs2++2bdvw66+/Yv/+/cjLy8PRo0cxZMgQ\niefy9/dHZmYmAODIkSPIz8+Hq6urWLmnT59i2LBhMDMzQ2pqKs6dOwd7e3t4enri2bNnbDmhUIhl\ny5Zh8+bNuHHjBpydnaX+jfbv348+ffrgrbfeQmBgIA4cOIDnz5+z2xmGga+vL44ePYpt27YhNzcX\ne/fuhampKQCguroaHh4euHz5Mg4cOICcnBxs27YNurq6Us8pzbJlyxAQEIBr165h7ty5YBgGZmZm\nOHjwIHJzc/H9998jJiYG33zzDbtPQkICRo8eDScnJ5w9exYZGRmYNm0a6uvr4enpCVtbW+zevVvk\nPFFRUZg8ebLU1x548b/z+++/IzAwEIMHD4a5uTl+/fVXsXLnz59HUlIS/vrrL/z999+4evUqgoOD\n2e2VlZXw8vLC8ePHcfXqVcyZMwczZsxAUlKSxPNyifnw4cNYv349tm7diry8PJw8eRLvv/++1LqE\nhobi4sWLOHLkCPLy8hAbG4u+fftKLT9ixAiR+BITE2FqaorExER2XVJSEry8vMT27datG44cOQIA\nyMzMRH5+Pg4fPsz57/UqgUAAfX19HDlyROT/sjmnTp2Cp6cnvvjiC2zatAk8Hk+sDJf3Um1tLRwc\nHBAXF4ecnByEhYVh5cqV+Omnn0SOlZmZicTERBw5cgSXL19mr3x///13FBcX4/Tp0/jll19w7Ngx\nbNiwgVMdZEah6UnJZGRkMACYQ4cOtVj21SsISd5++21m7dq1DMMwzMWLFxkAzN27dyWWDQoKYkaM\nGCHybeNlL19BMMz/vkWnpqay61791rNy5Upm8ODBIscRCoVM7969mS1btjAM87+rkZSUlOYr/P8N\nGDCAiYiIYJft7e1FvikmJCQwAJjz589L3H/Xrl2MlpaW2BWCtDo0kXQFsXr16hbj3bx5M2NjY8Mu\nDxs2jBkzZozU8ps2bWK6d+/ONDY2MgzDMLm5uQwA9kqvufMMGjSIXf72228ZNzc3kTLTp09nTE1N\nRa5o1q9fz1hYWDR77LFjxzKzZ88WOc7L/3stxbx582bG1taWqaurk3j8V68gxo4dy0yfPr3ZmF7W\n9Hpcv36dYRiG6dq1KxMeHs7WKycnhwHA3L59m2EY8dc4NTVV4nujrX+vw4cPM8bGxoyGhgbj5OTE\nBAUFMadOnRIp0/SN/cCBA4yenh6zf/9+ke1teS9JEhQUxHh7e4vUycDAQOzKwMPDg3n77bdF1s2d\nO5cZMmRIs3WVNbqCeAnzGvMWPnv2DPPmzUOfPn3QuXNnCAQCXL9+Hffv3wcAvP322xg9ejQcHBww\nbtw4bN26FQ8fPmT3nzFjBq5evQobGxvMnTsXhw4dQl1d3WvV5/z588jKymL7L5q+Xd27dw95eXki\nZbl0OGdkZCA3NxeTJ09m102fPh2RkZHsclZWFgwNDaVehWRlZaFfv36wsrJqY63+x8XFRWxdVFQU\n+w1eIBAgJCSEfQ2azj9q1Cipx5w+fToKCgrw999/AwB27doFJycnDBw4sNlYoqKiEBgYyC5PmTIF\nZ8+eFeus7tOnD7S0tNhlS0tLPH36lF2uqqrCV199hf79+8PIyAgCgQDx8fEidWhtzBMmTEB9fT16\n9OiBwMBA7Nu3DxUVFVKPN2/ePPz+++9wcHDAwoULcfz4cQiFQqnle/bsiZ49eyIxMRE3b95EaWkp\n5s2bh6qqKuTk5CAxMRHdu3eHtbW11GNI09LfS5Jx48bh8ePHOHHiBP71r38hJycHI0eOxPz580XK\nnThxAlOnTsUvv/yCgICAZo/J5b0kFAqxfv16ODo6wsTEBAKBAP/5z3/EXru+ffuK9Cc2GTBggMgy\nl7rKGiWIl9ja2kJNTQ05OTmt3jcwMBCpqan47rvvkJqaynbeNn3Iq6ur4/jx40hMTMQ777yDQ4cO\nwc7ODseOHQMAODo64u7duwgPD4empiYWLlwIR0dHlJeXt7k+QqEQI0eORHZ2tsjPzZs3sWrVKrac\nuro6tLW1WzxeZGQk6urqYG5uDj6fDz6fj9DQUFy4cAHZ2dltjvNlamov/iVfTtaNjY0SP6BebfL5\n7bffMH/+fPj7+yM+Ph6XLl3C119/jfr6es7nNzY2xkcffYSoqCjU1dVh7969mDNnTrP7pKSkIDc3\nF4sXL2b/Lj179oRQKMSPP/4oUvbVjnQejydS16VLl2L//v1YuXIlkpKSkJ2dDR8fn2a/LLQUc9eu\nXXHjxg3s3r0bZmZmWLNmDezt7UW+oLxs9OjRePDgAVasWIGamhpMmTIFXl5eaGxslBqDl5cXTp06\nhcTERAwbNgw6Ojpwd3dHYmIiEhMTJTYvcdHS30saLS0teHl5ISQkBCdPnsSaNWuwc+dOkZFSDg4O\n6NWrF/t3aw6X99KmTZvw7bffIigoCCdPnkR2djZmz54tdmxpTZWS6tpcYpYHShAvMTIywvvvv4/t\n27ejrKxMbHt9fb3Uds2UlBTMmzcPY8eOxVtvvYUuXbrgzp07ImV4PB5cXFywfPlypKSkwMPDAzEx\nMex2gUCAcePGISIiAhcuXEBubi6Sk5PbXB9nZ2dcv34dVlZWsLGxEflp6hPgqqysDLGxsdixY4fI\nG+Ty5ctwd3dnryKcnJxQUlKCCxcuSDyOk5MTcnJypI4vNzMzAwD8888/7Lrs7GxOHwopKSkYOHAg\nlixZAicnJ9ja2ooNnXRycsJ///vfZo/z6aef4s8//0RkZCSqq6sxadKkZsv/+OOPePfdd8U+PDZv\n3ox9+/ahpqamxdhfrkNAQAAmTJiAAQMGoHfv3mw/1uvErKWlhffeew/fffcdrl69iqqqKsTFxUk9\nnpGRESZNmoTIyEj89ddfSE5ObvaL04gRI5CcnIyEhASMHDkSwP+SxunTp5tNEE0fjM0loNfV1Ify\nct+blZUVkpOTcePGDYwbNw61tbVS9+fyXkpJScF7772HmTNnYuDAgbCxsRG7Uu9oKEG8YufOndDQ\n0ICTkxMOHjyInJwc3L59G/v374ezs7PUF9ze3h4HDhzA1atXkZ2djUmTJon8w6enp2PNmjXIyMjA\ngwcPcOrUKVy5cgX9+vUDAGzcuBEHDhzA9evXcffuXezevRvq6uqws7Nrc10WLFiAxsZGfPjhh0hN\nTcW9e/dw5swZrFixAunp6a061v79+6GmpoYZM2bAwcFB5CcgIIDtrPby8sLw4cPh7++PI0eO4O7d\nu0hLS8OuXbsAAJMmTUKPHj0wduxYJCQk4O7duzh16hRiY2MBADY2NujRowdWrVqFGzdu4MyZM1i8\neLHEjsNX2dvb4+rVqzhy5Aj+7//+D1u3bhXp8ASAsLAwHD9+HIsWLcKVK1dw8+ZN/PTTT7h58yZb\nZtiwYbC3t0dwcDAmTpwIfX19qeds6pyeOnWq2N9l9uzZqKqqkthZ3Vwdjhw5gszMTOTk5GDOnDki\nyVKa5mKOjo5GVFQULl++jPv37+PAgQOoqKhg//detWLFChw+fBg3b95EXl4eDhw4AIFAgO7du0s9\nv5eXF0pKSnD06FE2GXh5eeHYsWMoLi5uNkH06NEDampqiI+PR0FBgcQvZ1wVFRXB09MTe/bsQXZ2\nNu7du4djx44hJCQEvXr1EhuS3bVrVyQnJ+PevXsYO3YsqqurJR6Xy3vJ3t4ep0+fRlJSEm7duoXQ\n0FBkZGS0uS7KgBLEK7p3746LFy/Cz88Pq1atwqBBg+Dq6oqoqCgsXboUDg4OEveLiYmBUCiEi4sL\n/Pz88N5774m06xsYGODs2bP48MMPYWtri5kzZyIgIABhYWEAgE6dOmHz5s0YOnQo3nrrLfzxxx84\ndOgQ7O3t21wXc3NznD17FiYmJhg/fjzs7e0REBCA+/fvo0uXLq06VlRUFHx9fSWOlx8/fjyqq6vx\n888/g8fj4a+//oKPjw/mzp0Le3t7TJkyBYWFhQAAXV1dJCcnw8HBARMnTkTfvn0xf/589o3J5/MR\nGxuLgoICDBw4EPPnz8e6devYpqfmfPrpp5g6dSpmzJiBgQMHIiMjQ6QpDQBGjRqF+Ph4ZGRkYPDg\nwXBxccGePXvExqJ/8sknqKura7F5ac+ePQCADz/8UGybvr4+3n//fbFmpuZs2bIFPXr0wIgRIzBy\n5Eh07doVH330Ead9pcVsaGiImJgYeHp6om/fvti8eTN+/PFH9pv+q7S1tfH111/DyckJzs7OuHLl\nCo4fPy5xZF8TS0tL2NnZQV9fn+37ePvtt9G5c2fY2dmJ3KvzKnNzc3z77bdYv349unTpIvFvyZVA\nIICrqyt27NgBLy8v9O3bF0FBQfDy8kJycrLEew4sLCxw+vRpPHnyBL6+vqiqqpIYY0vvpbCwMHh4\neODDDz/E0KFDUVJSgqCgoDbXRRnwmNfpmSVERX355Zc4efIkLl26pOhQOOuIMRPlRndSE/KSsrIy\n3Lp1Cz/++CMiIiIUHQ4nHTFm0jHQFQQhL/H09ERGRgYmTpyI6OhoTk1bitYRYyYdAyUIQgghEtFX\nDUIIIRJRgiCEECJRh++k5jJGvL2YmJiwwzVVEdWv41LlugFUv/bG9ZkxckkQO3fuxMWLF2FgYIBN\nmzaJbWcYBjExMbh06RK0tLQwb9489O7dWx6hEUIIkUIuTUyenp5Yvny51O2XLl3CkydPEBERgTlz\n5rB33RJCCFEcuSSIfv36SZy9sMmFCxfg7u4OHo8HOzs7PH/+HCUlJfIIjRBCiBRK0QdRXFwMExMT\ndtnY2BjFxcUwNDQUK5uQkICEhAQAwPr160X2kzU+ny/X88kb1a/jUuW6AVQ/RVGKBNEa3t7e8Pb2\nZpfl2bFDHWUdmyrXT5XrBlD92hvXTmqlGOZqZGQk8scpKiqCkZGRAiMihBCiFAnC2dkZKSkpYBgG\nt27dgq6ursTmJUIIIfIjlyam77//Hjk5OaioqMDcuXMxYcIENDQ0AHgx/fLAgQNx8eJFBAUFQVNT\nE/PmzZNHWIQQQpohlwSxaNGiZrfzeDzMnj1bHqEQ0mE190yFljx+/LgdIyFvig7XSU3Im6q5D/nG\nT8ZCPeqoHKMhbwKl6IMghBCifChBEEIIkYgSBCGEEIkoQRBCCJGIEgQhhBCJaBQTIYTIQUccpkwJ\nghAl0rhwMlBV2bZ9Pxnb+p10BVDferBN5yOt0xGHKVOCIESZVFW26YOirZO9tSmpkDcG9UEQQgiR\niK4gCFEi8d57gdjSNuzZln0AeO/FB23bk7wBKEG8YTpiR9mbxCdhmvybmPyVr+27o1K1PiRKEG+Y\njthRRkiHoWJ9SNQHQQghRCJKEIQQQiSiJiZClExbmg2etvVkuoK27kkkULVBBpQgCFEibe0Dov4j\n5aBqgwyoiYkQQohEdAWhglRtqB0hHYkqNRFSglBFKjbUjpCOQtWaCKmJiRBCiESUIAghhEhECYIQ\nQohE1AehglRtLDYhRDEoQaggVRuLTQhRDGpiIoQQIhFdQRDSQbQ4VXsz22mqdsXriK8fJQgVpUo3\n65AXmvuQaGvzIJGfjvj6UYJQQap2sw4hRDGoD4IQQohElCAIIYRIRAmCEEKIRJQgCCGESEQJghBC\niESUIAghhEhECYIQQohElCAIIYRIRAmCEEKIRHQn9RumI84HQwhRDLkliOzsbMTExEAoFGLkyJHw\n8/MT2f7s2TP88MMPKC8vh0AgwOeffw5jY2N5hffG6IjzwRBCFINTE9P58+fR2NjY5pMIhUJER0dj\n+fLl2LJlC9LS0vDo0SORMvv27YO7uzvCw8Px0Ucf4eDBg20+HyGEkNfHKUH8+uuvmDNnDqKjo5GX\nl9fqk9y+fRsWFhYwNzcHn8+Hq6srzp8/L1Lm0aNHcHBwAAD0798fFy5caPV5SNvExcXBy8sLOjo6\n8PLyQlxcnKJDIoQoAU5NTBs3bsS9e/eQmpqKTZs2QUtLC+7u7hg+fDjMzMxa3L+4uFikucjY2Fgs\n0fTo0QOZmZnw8fFBZmYmqqurUVFRAX19fZFyCQkJSEhIAACsX78eJiYmXKrQLvh8vlzPJw+xsbHY\nuHEjIiMj4eHhgeTkZHz66afQ19eHv7+/osNrV6r4+jVR5boBVD9F4dwH0bNnT/Ts2RNTpkzB1atX\nsW/fPvz666/o06cPvL294ebmBjW1tg+Kmjp1Knbv3o3Tp0+jb9++MDIykng8b29veHt7s8vybDNX\nxTb6devW4bvvvoODgwN4PB4cHBzw3XffISwsDCNHjlR0eO1KFV+/JqpcN4Dq194sLS05lWtVJ/WT\nJ0+QmpqK1NRU8Hg8+Pv7w8TEBCdOnEBGRgaCg4Ml7mdkZISioiJ2uaioCEZGRmJlmvavqalBRkYG\n9PT0WhMeaYO8vDy4uLiIrHNxcWlTUyIhRLVwShAnTpxAamoq8vPz4erqigULFsDOzo7dPnjwYMye\nPVvq/tbW1sjPz0dBQQGMjIyQnp6OoKAgkTJNo5fU1NTwxx9/YMSIEW2sEmkNW1tbZGZmws3NjV2X\nmZkJW1tbBUZFCFEGnBJEdnY2fH194ezsDA0NDbHtWlpaUq8eAEBdXR0zZ87EunXrIBQKMWLECHTr\n1g2xsbGwtraGs7MzcnJycPDgQfB4PPTt2xezZs1qe60IZ0FBQQgODkZ4eDh8fHyQlpaG4OBgLFu2\nTNGhEUIUjMcwDNNSobq6OqipqYHP/18+aWhoAMMwEhOGPP3zzz9yO5eqtoPGxcUhIiICeXl5sLW1\nRVBQkNh9KqpAVV8/QLXrBlD92hvXPghOvcrr1q3DnTt3RNbduXMH69ata31kROn4+fkhMTER1dXV\nSExMVMnkQAhpPU4J4v79+2Jt0jY2Nrh//75MgiKEEKJ4nBKEnp4eysrKRNaVlZVBS0tLJkERQghR\nPE4JYvDgwdi6dSsePHiA2tpaPHjwANu3b8fQoUNlHR8hhBAF4TSKaeLEidi7dy+WL1+O+vp6aGpq\nwtPTE5MmTZJ1fIQQQhSEU4LQ1NTE7NmzMWvWLHb6Cx6PJ+vYCCGEKFCr7qSuqalBTU0Nqqur2XXm\n5ubtHhQhhBDF45QgHj16hIiICImjlmJjY9s9KEIIIYrHqZN6165d6N+/P3bv3g1dXV3ExMTg3Xff\nxfz582UdHyGEEAXhfB9EQEAA9PT0wDAMdHV1MWXKFLp6IIQQFcYpQWhoaLBPlNPX10dhYSEYhkFl\nZaVMgyOEEKI4nPog+vTpg7Nnz8LT0xNDhgzBN998Aw0NDfTv31/W8RFCCFEQTgliyZIl7O+TJk1C\nt27dUFNTA3d3d5kFRgghRLFabGISCoVYtWoV6uvrX+ygpgZ3d3eMGjUK2traMg+QEEKIYrSYINTU\n1FBQUAAOs4ITQghRIZw6qT/66CNERUXh2bNnEAqFIj+EEEJUE6c+iMjISABASkqK2DYa6koIIaqJ\nU4LYvn27rOMghBCiZDglCFNTU1nHQQghRMlwShDbtm2TOnvrggUL2jUgQgghyoFTgrCwsBBZLi0t\nxblz5zB8+HCZBEUIIUTxOCWIjz/+WGydl5cXfvvtt3YPiBBCiHLgNMxVkp49eyI3N7c9YyGEEKJE\nOF1BXLt2TWS5trYWaWlpsLKykklQhLSnuLg4REREIC8vD7a2tggKCoKfn5+iwyJE6XFKED/88IPI\nsra2Nnr06IGFCxfKJChC2ktcXBy+/vpr6OrqAgCqqqrw9ddfAwAlCUJawGM6+Bwa//zzj9zOZWJi\ngsLCQrmdT95UsX7Ozs5obGzE9u3b4ePjg/j4eCxYsADq6uq4cOGCosNrN6r42r2M6te+LC0tOZXj\n1Adx+fJlsQ/if/75B1euXGl9ZITIUX5+Pr7//nu4ublBQ0MDbm5u+P7775Gfn6/o0AhRepwSRHR0\nNHR0dETWaWtrIzo6WiZBEUIIUTxOCaKsrAyGhoYi6wwNDVFaWiqToAhpL126dMGiRYuQlpaG+vp6\npKWlYdGiRejSpYuiQyNE6XHqpDY3N8e1a9fg4ODArrt+/TrMzMxkFhgh7SE0NBRff/01vvjiC/j7\n+8PKygqNjY1YuXKlokMjr+jatWub9338+HE7RkKacL5RLjw8HF5eXjA3N8fTp0+RlJSEefPmyTo+\nQl5L00iliIgI8Hg86Orq4quvvqIRTEqouQ/5xk/GQj3qqByjIUArRjHdvn0biYmJKCoqgrGxMby8\nvGBjYyPr+FpEo5jaD9Wv41LlugGqnyCUdRQTpysIALCxsVGKhEAIIUQ+OCWI8PBwjBkzBn379mXX\n5ebmIj4+Hl988YXMgiOktagdm5D2wylB5OTkYMmSJSLr7OzssHHjRpkERUhbUTs2Ie2H0zBXDQ0N\n1NTUiKyrqamBurq6TIIihBCieJwSxIABA/Djjz+iqqoKwIv5bKKjo+Ho6CjT4AghhCgOpyamadOm\nYdu2bZg5cyYEAgEqKyvh6OhIT5MjhBAVxilBCAQChISEoLS0FIWFhTAxMUHnzp1bdaLs7GzExMRA\nKBRi5MiRYuPQCwsLsWPHDjx//hxCoRCTJ0/GoEGDWnUOQggh7adVDwzq3LkzbGxswOfzceLECYSE\nhHDaTygUIjo6GsuXL8eWLVuQlpaGR48eiZQ5dOgQhg4diu+++w6LFi2ieZ4IIUTBON8H0djYiIsX\nLyI5ORmXLl2CkZER3n33XU773r59GxYWFjA3NwcAuLq64vz58yIPHOLxeCJ9HK/O/UQIIUS+WkwQ\nd+7cwenTp5GWlgahUAgXFxdoaGhg7dq1MDAw4HSS4uJiGBsbs8vGxsbIy8sTKfPxxx9j7dq1OHHi\nBGpraxEWFtbKqhBCCGlPzSaIL774Ak+fPsXAgQMxZ84cDBo0CBoaGrh06VK7B5KWlgZPT0988MEH\nuHXrFrZt24ZNmzZBTU20FSwhIQEJCQkAgPXr18PExKTdY5GGz+fL9Xzypur1ewqobP3otevYlPX1\nazZB1NbWQk1NDZqamtDS0gKfz7lFSoSRkRGKiorY5aKiIhgZGYmUSUxMxPLlywG8uAmvvr4eFRUV\nYlcp3t7e8Pb2ZpflOX+Jqs93o+r1A+T7/yJP9Np1bB1yLqbt27cjJycHycnJ2LJlCzQ1NTF06FDU\n19eDx+NxDsba2hr5+fkoKCiAkZER0tPTERQUJFLGxMQE165dg6enJx49eoT6+np06tSJ8zkIIYS0\nL86zudYbdpTvAAAeCklEQVTV1eHcuXNISUnBtWvXYGlpidGjR2P06NGcTnTx4kXs2bMHQqEQI0aM\nwPjx4xEbGwtra2s4Ozvj0aNHiIyMZO/YnjJlCgYMGNDicWk21/bTUerXuHAyUFUpvxPqCqC+9aD8\nztcGHeW1aytVnyalQ15BvExTUxPu7u5wd3dHcXExkpOTceLECc4JYtCgQWL3Nfj7+7O/W1lZYc2a\nNVzDIW+yqso2fVi09U3Y+MnYVu9DiCpoU6eCkZERxo0bh3HjxrV3PIQQQpREq26UI4QQ8uagBEEI\nIUSito1bJUSB4r33ArGlbdizLfsA8N6LD9q2JyEdWqsThFAoFFl+9UY2QmTNJ2Ga/Dup/VV3BA0h\n0nBKEHfu3EF0dDQePHiAuro6kW2xsbEyCYwQonpeZ4hym0aTdYAhysqMU4LYsWMHnJyc8Nlnn0FL\nS0vWMRFCVBUNUe5QOCWIwsJCTJo0qVV3TxNCCOnYOHUgvPPOO7h8+bKsYyGEEKJEOF1B1NfXIzw8\nHH369BF7khw9dpQoQluaDp629WS6grbuSUiHxilBWFlZiTzchxBFauucPKo+nw8h7Y1Tgvj4449l\nHQchhBAlw/k+iOvXryM5ORklJSUwNDSEu7s7HBwcZBmb0oiLi0NERATy8vJga2uLoKAg+Pn5KTos\nQgiRKU6d1KdOncKWLVvQuXNnuLi4wNDQEFu3bmWf7KbK4uLisGHDBqxZswbl5eVYs2YNNmzYgLi4\nOEWHRgghMsXpCuLo0aMIDQ1Fz5492XWurq7YtGmTyNPdVFFERATCw8Ph5uYGDQ0NuLm5ITw8HGFh\nYXQVQQhRaZyuICoqKsQ6qS0tLVFZKceHtihIXl4eXFxcRNa5uLggLy9PQRERQoh8cLqC6NOnD/bu\n3YuAgABoaWmhpqYGBw8ehJ2dnazjUzhbW1tkZmbCzc2NXZeZmQlbW1sFRkVIx0QTLXYsnBLEJ598\ngu+//x6BgYEQCASorKyEnZ0dFi5cKOv4FC4oKAjBwcEIDw+Hj48P0tLSEBwcjGXLlik6NEI6HJpo\nsWPhlCAMDQ3x73//G4WFhSgtLYWhoSGMjY1lHZtCdO3aVeL6CRMmiCzPnz8f8+fPF1n3+PFjmcVF\nCCHyJjVBMAzDzr3UNMW3kZERjIyMRNap2nTfzX3I041WhJA3idQEERgYiD179gAAJk2aJPUANN03\nIYSoJqkJYtOmTezv27dvl0swhBBClIfU9iETExP297Nnz8LU1FTsJyMjQy5BEkIIkT9OndSHDh3C\n2LHis2ceOnQIvr6+7R4UIW0lbZDBSwWkbqJBBoSIajZBXLt2DcCLDumm35s8ffoUOjo6souMkDZo\n7kO+rUMlCXlTNZsgfvjhBwBAXV0d+zsA8Hg8GBgYYObMmbKNjhBCiMI0myB27NgB4EUnNT0YiBBC\n3iycbmLw9fUVuzQvLCzEvXv3ZBETIYQQJcApQWzbtg2NjY0i6xoaGmj4KyGEqDBOo5gKCwthbm4u\nss7CwgLPnj2TSVCEtKfQ0FAcOHAAdXV10NTUREBAANauXavosN5Y9DzxjoNTgjAyMsKdO3fQu3dv\ndt2dO3dgaGgos8AIaQ+hoaHYu3cvVqxYgcWLF2PLli1Yt24dAFCSUAB6nnjHwilBjBkzBhs3bsTY\nsWNhbm6Op0+f4s8//8T48eNlHR8hr+XAgQNYsWIFPv30U+jq6uLTTz8FAKxfv54SBCEt4JQgvL29\noaenh8TERBQVFcHY2BjTpk3DkCFDZB0fIa+lrq4OU6dOFVk3depUrF69WkEREdJxcEoQADB06FAM\nHTpUlrEQ0u40NTWxb98+9soBAPbt2wdNTU0FRkVIxyA1QaSkpMDd3R0AkJiYKPUAXl5e7R+VjDUu\nnAxUte1xqW3pYIOuAOpbD7bpfOT1BAQEsH0OixcvRmRkJNatW4dp06YpODJClJ/UBJGWlsYmiNTU\nVKkH6IgJAlWV8n+qFVGIpn6G9evXY/Xq1dDU1MS0adOo/4EQDqQmiJCQEPb3lStXyiUYQmRh7dq1\nWLt2Lc3FREgrSU0QTU+Ma4mqPVGOEELIC1ITRHNPkXsZPVGOEEJUk9QE8fI0GhcvXsS5c+cwbtw4\n9jL9yJEjGDx4MOcTZWdnIyYmBkKhECNHjoSfn5/I9p9++gnXr18H8GJoYllZGX766adWVoebeO+9\nQGxpG/Zsyz4AvPfig7btSQghCiM1QZiamrK/Hzt2DOvXr4eenh4AwNLSEr1790ZISAhGjRrV4kmE\nQiGio6MRGhoKY2NjhISEwNnZGVZWVmyZwMBA9vfjx4/j7t27bakPJz4J0+TfSe1Pd4ESQjoWTh0I\nVVVVqK2tFVlXV1eHqqoqTie5ffs2LCwsYG5uDj6fD1dXV5w/f15q+bS0NAwbNozTsQkhhMgGpxvl\nPDw8sGbNGowZMwbGxsYoKirC8ePH4eHhwekkxcXFMDY2ZpeNjY2Rl5cnseyzZ89QUFAABwcHTscm\nhBAiG5wSxJQpU2BhYYH09HSUlJSgc+fOGD16NLy9vds9oLS0NAwZMkTq6KiEhAQkJCQAeDG23cTE\npNXneAq0aT8+ny/X88lbW+vXUahy/VS5bkDHeQ+1lbK+fpwShJqaGkaNGsWpv0ESIyMjFBUVsctF\nRUUwMjKSWDY9PR2zZs2Seixvb2+RxNTWce1t2e91xtF3hPH3qn6fgCrXT5Xr1kSV6yfv18/S0pJT\nOU4JgmEYnDp1Cunp6SgvL0d4eDhycnJQWloKV1fXFve3trZGfn4+CgoKYGRkhPT0dAQFBYmVe/z4\nMZ4/fw47OztOwb8OmpOeEEKaxylBxMbG4urVq/Dx8UFUVBSAF/0Ie/bs4ZQg1NXVMXPmTKxbtw5C\noRAjRoxAt27dEBsbC2trazg7OwN40bzk6uoKHo/3GlVqGc1JTwghLeOUIJKTk7FhwwZ06tQJu3bt\nAgCYmZmhoKCA84kGDRqEQYMGiazz9/cXWZ4wYQLn4xFCCJEtTsNchUIhtLW1RdbV1NSIrSOEEKI6\nOCUIR0dH7N27F/X19QBe9EnExsbCyclJpsERQghRHE4JYvr06SgpKUFgYCCqqqowbdo0PHv2DAEB\nAbKOjxBCiIK02AfBMAwqKiqwZMkSVFZW4tmzZzAxMUHnzp3lER8hhBAFafEKgsfjITg4GDweDwYG\nBrCxsaHkQAghbwBOTUw9e/ZEfn6+rGMhhBCiRDgNc+3fvz+++eYbeHh4iN0O3iEfOUoIIaRFnBLE\nzZs3YWZmhtzcXLFtlCAIIUQ1cUoQ9ExqQgh58zSbIGpra3Ho0CE8fPgQvXr1wrhx46ChoSGv2Agh\nhChQs53U0dHRyMrKQteuXZGRkYF9+/bJKy5CCCEK1myCyM7ORmhoKKZMmYKQkBBkZWXJKy5CCCEK\n1mITk6GhIYAX85VzfcQoIYS0VteuXVsqIHXT48eP2zkaArSQIBobG3Ht2jV2WSgUiiwDULlHg9I/\nKSGK0dz75014IJIyajZBGBgY4IcffmCXBQKByDKPx8P27dtlF50CvPpPGhcXhw0bNiA8PBw+Pj6I\nj49HcHAwli1bBj8/PwVFSQghstdsgtixY4e84lBaERERCA8Ph5ubGzQ0NODm5obw8HCEhYVRgiCE\nqDROU228yfLy8vDkyRN4eXlBR0cHXl5eePLkCfLy8hQdGiGEyBSnG+XeZObm5li7di22b9/ONjEt\nWLAA5ubmig6NEEJkiq4gCCGESEQJogVPnz7FihUrEBYWhk6dOiEsLAwrVqzA06dPFR0aIYTIFDUx\ntcDW1hZdunRBYmIiO9QuLS0Ntra2ig6NEEJkiq4gWhAUFITg4GCkpaWhvr4eaWlpCA4ORlBQkKJD\nI4QQmaIriBY0DWUNCwvDxIkTYWtrS/dAEELeCHQFwYGfnx8SExNRXV2NxMRESg6EyElcXJzIEPO4\nuDhFh/RGoSsIQohSkjaLAQD6kiYndAVBCFFK0mYxiIiIUHRobwxKEIQQpZSXlwcXFxeRdS4uLjSL\ngRxRgiCEKCVbW1tkZmaKrMvMzKQh5nJECYIQopRoiLniUSc1IUQp0RBzxaMEQQhRWn5+fvDz86MH\nBikINTERQgiRiBIEIYQQiShBEEIIkYgSBCGEEIkoQRBCCJGIEgQhhBCJKEEQQgiRiBIEIYQQieR2\no1x2djZiYmIgFAoxcuRIiXdDpqen47fffgOPx0OPHj2wcOFCeYVHCCHkFXJJEEKhENHR0QgNDYWx\nsTFCQkLg7OwMKysrtkx+fj7i4uKwZs0aCAQClJWVySM0QgghUsilien27duwsLCAubk5+Hw+XF1d\ncf78eZEyp06dwujRoyEQCAAABgYG8giNEEKIFHK5giguLoaxsTG7bGxsLDan+z///APgxcRcQqEQ\nH3/8MRwdHeURHiGEEAmUZrI+oVCI/Px8rFy5EsXFxVi5ciXCw8Ohp6cnUi4hIQEJCQkAgPXr18PE\nxERuMfL5fLmeT96ofh2XKtcNoPopilwShJGREYqKitjloqIiGBkZiZWxtbUFn8+HmZkZunTpgvz8\nfNjY2IiU8/b2hre3N7sszxkeVX1GSapfx6XKdQOofu3N0tKSUzm59EFYW1sjPz8fBQUFaGhoQHp6\nOpydnUXKuLi44Pr16wCA8vJy5Ofnw9zcXB7hEUIIkUAuVxDq6uqYOXMm1q1bB6FQiBEjRqBbt26I\njY2FtbU1nJ2dMWDAAFy+fBmLFy+GmpoapkyZAn19fXmERwghRAIewzCMooN4HU2d2/JAl7kdmyrX\nT5XrBlD92ptSNTERQgjpeChBEEIIkYgSBCGEEIkoQRBClFZcXBy8vLygo6MDLy8vxMXFKTqkN4rS\n3ChHCCEvi4uLw4YNGxAeHg4fHx/Ex8cjODgYACRO9knaH11BEEKUUkREBMLDw+Hm5gYNDQ24ubkh\nPDwcERERig7tjUEJghCilPLy8uDi4iKyzsXFRWweNyI7lCAIIUrJ1tYWmZmZIusyMzNha2uroIje\nPJQgCCFKKSgoCMHBwUhLS0N9fT3S0tIQHByMoKAgRYf2xqBOakKIUmrqiA4LC8PEiRNha2uLZcuW\nUQe1HFGCIIQoLT8/P/j5+an8VBvKipqYCCGESEQJghBCiESUIAghhEhECYIQQohElCAIIYRI1OEf\nGEQIIUQ26AqiFb766itFhyBTVL+OS5XrBlD9FIUSBCGEEIkoQRBCCJFIfdWqVasUHURH0rt3b0WH\nIFNUv45LlesGUP0UgTqpCSGESERNTIQQQiSiBEEIIUQims0VQGlpKfbs2YO8vDzo6emBz+fjww8/\nhJ6eHv7973/jyy+/hLOzMwBg/fr1+OCDD9C/f3+sWrUKJSUl0NTURENDA8aMGQNvb28F10bc1KlT\nsW/fPgDAxYsXsWfPHoSGhiIpKQlHjx7Fjh07YGBgIFZ2woQJ8PX1xbRp0wAAR48eRU1NDSZMmKCY\nikjxcswvS0hIwLFjxwAAOjo6mD59Ovr06QMAaGxsRGxsLM6dOwctLS0AwNChQzF+/Hj5Bd5G/v7+\n6N69O4RCIUxNTfH5559DT08PBQUFWLx4MSwtLdmy3377Lfh85XqbHz58GGfOnIGamhp4PB7mzJmD\n3r17N/t6NNW5sbER6urqcHd3x5gxY6Cm9uI77u3bt7Fv3z6UlpZCS0sLvXv3xowZM9hjKdKr9XVx\ncUF9fT0mT57Mlrl37x62bt2KLVu2YP78+TA2Nsbq1avZ7UuXLoVQKMSmTZvkGrty/ecoAMMw2Lhx\nIzw8PLBw4UIAwLNnz3DhwgXo6enB2NgYf/zxB5sgXhUUFARra2tUVlbi888/h6enp9K9IZtcvXoV\nMTExWLFiBUxNTQEA+vr6+PPPPzFlyhSx8hoaGsjIyICfnx86deok73BfS1ZWFk6ePInVq1ejU6dO\nuHPnDjZu3Ihvv/0WnTt3xi+//ILS0lKEh4dDU1MT1dXV+PPPPxUdNieamprYuHEjAGD79u34+++/\n2Q9SCwsLdpsyunXrFrKysrBhwwZoaGigvLwcDQ0NLb4eL9e5rKwMERERqK6uxoQJE1BaWorNmzdj\n0aJFsLOzAwCcO3cO1dXVCk8Qkur76NEj7Ny5UyRBpKWlwc3NjV2urq5GYWEhTExM8OjRI0WEDoCa\nmHDt2jXw+XyMGjWKXWdqaor3338fANCjRw/o6uriypUrzR6npqYGWlpa7DcaZZOTk4PIyEh89dVX\nsLCwYNePGDECZ8+eRWVlpdg+ampq8Pb2xl9//SXPUNvFkSNHMHXqVDax9e7dGx4eHjhx4gRqa2tx\n6tQpzJw5E5qamgBeXGEo25URF3Z2diguLlZ0GJyVlJRAX18fGhoaAIBOnTpBT0+vVa+HgYEB5syZ\ngxMnToBhGPz999/w8PBgkwMADBkyBJ07d5Z9hVogqb79+vWDnp6eyLO1z549K5Ighg4divT0dADi\nyUOelPPTTI4ePnyIXr16NVtm3LhxOHTokMRtERERCA4OxsKFC/Gvf/1LKRNEQ0MDNm7ciKVLl6Jr\n164i27S1tTFixAjEx8dL3Hf06NE4c+YMqqqq5BFqu3n48KHYsEFra2s8evQIT548gYmJCXR0dBQU\nXfsQCoW4du2ayNXtkydPsHTpUixduhS7du1SYHSSDRgwAEVFRVi4cCF27dqFnJycNr0e5ubmEAqF\nKCsrk/haKwtJ9QUANzc3pKWlAXhxlSEQCNClSxd2vyFDhrDP487KypLagiFrytkWokC7du3CzZs3\nwefz2WaXfv36AQBu3LghVr6piam8vByhoaFwdHRkm2+Uhbq6Ouzt7ZGYmIgZM2aIbX///ffx5Zdf\n4oMPPhDbpqurC3d3d8THx7Pf7lRNUlIS4uPjUVlZiTVr1sDExETRITWrrq4OS5cuRXFxMaysrPD2\n22+z25S9iUlbWxsbNmxAbm4url+/ji1btmDcuHEiZTra69EcSfUNCAiAq6srwsLCMG3aNKSnp4td\nIQgEAujp6SEtLQ1du3ZV2HtP+b7uylm3bt1w9+5ddnn27NkICwtDeXm5SLnx48dLvYoAXlw69urV\nS+SyUVnweDwsXrwYt2/fxuHDh8W26+npwc3NDX///bfE/ceMGYOkpCTU1tbKOtR2Y2VlhTt37ois\nu3PnDqysrGBhYYHCwkJUV1cDeNHMtnHjRujq6kIoFCoi3FZpao/fuXMnGIbBiRMnFB1Sq6ipqaF/\n//6YMGECZs2ahaysrFa/Hk+fPoWamhoMDAwkvtbK5NX6njt3DiYmJjAzM0NOTg4yMjLg6uoqtp+r\nqyuio6MV1rwEUIKAg4MD6uvr8d///pddV1dXJ1ZuwIABeP78Oe7fvy/xOLW1tbh3755I+74y0dLS\nQkhICM6cOYPExESx7b6+vjh58qTEN6RAIMDQoUMl7qesPvzwQxw4cAAVFRUAXowSOX36NEaPHg0t\nLS14eXkhOjqafa2FQiEaGhoUGXKraWlpYcaMGTh27BgaGxsVHQ4n//zzD/Lz89nle/fuwdLSslWv\nR3l5OaKiovDee++Bx+PhvffeQ3JyssiXs4yMDJSWlsq2MhxIqm9TC4Obmxv27NkDMzMzGBsbi+3r\n4uKCsWPHwtHRUW7xvuqNb2Li8XhYunQp9uzZgyNHjqBTp07Q1tZGQECAWNnx48fju+++E1kXERHB\nDnP18PBQ2rZQ4MUH/fLly7Fy5UqxUUmdOnWCi4uL1A5pX19fpf2mWldXh7lz57LLvr6+8PX1RXFx\nMUJDQ8Hj8aCjo4PPP/8choaGAICJEyciNjYWX3zxBXR0dKCpqQkPDw8YGRkpqhpt0qtXL3Tv3h1p\naWnsEF5lVlNTg927d+P58+dQV1eHhYUF5syZA11d3WZfj6ZmtaZhrsOHD4evry8AoHPnzli0aBH2\n7duHsrIyqKmpoW/fvgr9YG0irb7Ai36GmJgYic2+wIuOej8/P3mGK4am2iCEECLRG9/ERAghRDJK\nEIQQQiSiBEEIIUQiShCEEEIkogRBCCFEIkoQpEP79ddfERERIbPjL1myBNevXwfwYmLHnTt3YsaM\nGQgJCUFubi47waMymz9/fotziQFAQUEBJkyY0GHuqSCy98bfB0GU35kzZ3Ds2DE8fvwYOjo66Nmz\nJ8aPHy+Xcf+bN29mf79x4wauXLmCH374Adra2gCArVu3ttu5duzYgeTkZCxduhTvvPMOu/6nn35C\nfHw85s2bB09Pz3Y7HyEtoQRBlNqxY8cQFxeHTz75BAMGDACfz0d2djbOnz8v9xvDnj17BlNTUzY5\nvI6mG75e1aVLFyQnJ7MJorGxEWfPnoW5uflrn5OQ1qIEQZRWVVUVYmNjMW/ePAwePJhd7+zsLHV2\ny82bNyM3Nxd1dXXo2bMnZs+ejW7dugF48bCkffv2oaioCDo6OhgzZgzGjh2L8vJy7Ny5Ezdu3ACP\nx0O3bt2watUqqKmpYf78+fj0009RWFiI6OhoNDQ0YOrUqexDo7Zt24b//Oc/AIDi4mLs3r0bubm5\n0NbWxpgxY+Dj4wPgRVPYw4cPoaGhgaysLEybNg0jR44Ui9/JyQmpqamorKyEQCBAdnY2evTowc5T\nBLyYhuKPP/7AqVOnUFdXB0dHR8ycORO6uroAgJSUFPzyyy+oqalh7zZ+ed+jR4/i1KlTeP78ORwc\nHDBnzhwIBILXeKWIqqI+CKK0bt26hfr6eri4uHDex9HREREREdi1axd69eol0j/xn//8B3PmzMHe\nvXuxadMmODg4AHhxlWJkZIRdu3YhKioKkyZNAo/HEzmul5cXPvnkE9jZ2WHfvn1izyoQCoXYsGED\nevbsicjISHz99deIj49HdnY2W+bChQvs9ArDhw+XGL+mpiacnZ3ZZwEkJyfD3d1dpMzp06dx+vRp\nrFy5Etu3b0dNTQ2io6MBAI8ePUJUVBQWLFiAyMhIVFRUoKioiN33xIkTOH/+PFatWoXIyEgIBAKl\nnBacKAdKEERpVVRUQF9fX2JTjDReXl7Q0dGBhoYGPv74Y9y/f599loW6ujoePXqEqqoqCAQCdt4s\ndXV1lJaWorCwEHw+H3379hVLEC35v//7P5SXl+Ojjz4Cn8+Hubk5Ro4cyX7QAy8e7uPi4gI1NbVm\np2/28PBAcnIynj9/jtzcXLEEeebMGfj6+sLc3Bza2tqYPHky0tPT0djYiHPnzsHJyQn9+vWDhoYG\n/P39Repy8uRJTJw4EcbGxuzfKCMjgzqmiUTUxESUlr6+PioqKqS2179KKBTi559/xrlz51BeXs5+\nMJaXl0NXVxdffPEFDh8+jIMHD6J79+4ICAiAnZ0dxo4di99++w1r164FAHh7e7d6krRnz56hpKQE\ngYGBIvH07duXXZY0Y6ckffr0QXl5OQ4fPoxBgwaJJZOSkhKRZ46YmJigsbERZWVlKC4uFjmPtrY2\n9PX1ReIMDw8XSRpqamooKyvjXFfy5qAEQZSWnZ0dNDQ0cP78eQwZMqTF8mfOnMGFCxcQFhYGU1NT\nVFVVicyUaWNjgy+//BINDQ04ceIEtmzZgh9++AE6OjqYNm0apk2bhgcPHmD16tWwtrbGW2+9xTnW\npvn922vI7fDhw3Ho0CGsXLlSbJuhoSGePXvGLhcWFkJdXR0GBgYwNDTE48eP2W21tbXslOfAiyT1\n2WefSezgLygoaJfYieqgJiaitHR1dTFhwgRER0cjMzMTtbW1aGhowKVLl7B//36x8tXV1eDz+RAI\nBKitrcXPP//MbmtoaEBqaiqqqqrA5/Ohq6vLfovOysrCkydPwDAMdHV1oaam1uomJhsbG+jo6CAu\nLg51dXUQCoV48OABbt++3aa6+/j4IDQ0VOQKpImbmxv++usvFBQUoKamBj///DOGDh0KdXV1DBky\nBFlZWbhx4wYaGhoQGxuLlydsfvfdd/HLL7+wCaa8vBznz59vU4xE9dEVBFFqH3zwATp37ozDhw9j\n27Zt0NbWRu/evTF+/Hixsh4eHrh8+TLmzp0LgUAAf39/kQdBpaSkYPfu3RAKhbC0tERQUBAAID8/\nH7t370Z5eTn09PQwatQotgObKzU1NSxbtgx79+7F/Pnz0dDQAEtLS/j7+7ep3gKBQOoVzIgRI1BS\nUoKVK1eirq4OAwYMwMyZMwG8eELirFmzsHXrVtTW1sLX11ekyalpVNXatWtRUlICAwMDDB06VOS+\nC0Ka0PMgCCGESERNTIQQQiSiBEEIIUQiShCEEEIkogRBCCFEIkoQhBBCJKIEQQghRCJKEIQQQiSi\nBEEIIUSi/wfeem3CrFOrUwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10f685e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "main(data, 100, 0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Woah, it looks like there are some clear winners. The **Random Forest model seems to perform the best**, with **Support Vector Machines** taking second. **K-Nearest Neighbors** -- the **simplest ML model ever** -- took third. \n",
    "\n",
    "Feel free to play around with this data and try out different models with different test_ratios. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
