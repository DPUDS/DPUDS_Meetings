{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ** K-Nearest Neighbors Classifier **\n",
    "\n",
    "A simple Data Science model, the KNN Classifier predicts the class of unknown data points by referencing them against its \"neighbors,\" the data points closest to it. This model makes use of a breast cancer dataset and determines whether or not a tumor is malignant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First, lets import all of our dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All dependencies successfully imported.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "from math import sqrt\n",
    "import pandas as pd\n",
    "import random\n",
    "from statistics import mode\n",
    "import os\n",
    "print(\"All dependencies successfully imported.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next, we need to change our working directory so our program can find the breast cancer dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.chdir('/Users/Sam/Documents/Python/Datasets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now, the data needs to be read into a dataframe, and organized into a suitable format. Most importantly, we need to ensure that the feature data and the label data is separated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Reading in the data set to a dataframe\n",
    "orig_data = pd.read_csv('breast_cancer.txt')\n",
    "\n",
    "#Next, separate the data into the features (predictors) and labels (classes: malignant or benign)\n",
    "data = orig_data.drop(['class', 'patient_id'], axis = 1)\n",
    "label = orig_data['class']\n",
    "\n",
    "#Now we need to replace missing values in the data with the number zero.\n",
    "data['bare_nuclei'].replace('?',0.0, inplace = True)\n",
    "data['bare_nuclei'] = data['bare_nuclei'].astype('float')\n",
    "\n",
    "#Convert both features (data) and labels\n",
    "data = list(data.values)\n",
    "label = list(label)\n",
    "\n",
    "#Reference dictionary for easy to read results. \n",
    "dict = {2:'benign',4:'malignant'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With the data ready for analysis, let's begin to construct our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Creating a comparison engine:** \n",
    "The point of this model is to find the neighbors of a given data point, those that are most similar. However, how can we determine which points are similar? The two most common functions are a Euclidian Distance Function and a Pearson Correlation Coefficient (r). \n",
    "\n",
    "This method is an **estimate** of the Pearson Coefficient\n",
    "\\begin{align}\n",
    "r = \\frac{{}\\sum_{i=1}^{n} (x_i - \\overline{x})(y_i - \\overline{y})}\n",
    "{\\sqrt{\\sum_{i=1}^{n} (x_i - \\overline{x})^2(y_i - \\overline{y})^2}}\n",
    "\\end{align}\n",
    "\n",
    "The **exact Pearson Coefficient** formula is shown below**\n",
    "\\begin{align}\n",
    "\\rho = \\frac{\\text{cov}(X,Y)}{\\sigma_x \\sigma_y}\n",
    "\\end{align}\n",
    "\n",
    "**Where cov(X,Y) is equal to**\n",
    "\\begin{align}\n",
    "cov(X,Y) = \\sum_{i=1}^{n}(x_i - \\bar{x})(y_i - \\bar{y})\n",
    "\\end{align}\n",
    "\n",
    "**and**\n",
    "\\begin{align}\n",
    "\\sigma{_x} = \\sqrt{\\sum_{i=1}^{n}(x_i - \\bar{x})^2\\quad}\n",
    "\\end{align}\n",
    "\n",
    "However, the **Euclidian** distance function is the simplest\n",
    "to understand, and will be used in our model.\n",
    "\\begin{align}\n",
    "e = \\sqrt{\\sum_{i=1}^n (x_i-y_i)^2}\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "Where x is a record (**person**) and y is another. Below is our euclidian function; this will calculate the distance between two different records and tell us how similar they are (smaller number = greater similarity)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Must sort from smallest to largest to get similarity rankings.\n",
    "def euclid(x,y):\n",
    "    sums = 0.0\n",
    "    for i in range(len(x)):\n",
    "        sums += pow((x[i] - y[i]),2)\n",
    "\n",
    "    return sqrt(sums)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we need to make functions to analyze the data. In order to do so effectively, we have to create a train and test set of data. The function below approximately splits the data into two samples with sizes specified by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Split data to train and test samples\n",
    "#The random.random() function decides whether an item goes into the train or test set\n",
    "#train_count and test_count keep track of how many records are in each sample\n",
    "#x_traintest acts as a reference bank for all testing data later. It will be what \"unknown\" ...\n",
    "#data points are compared against\n",
    "def train_test_split(data,label, test_ratio):\n",
    "    x_traintest = []\n",
    "    x_test = []\n",
    "    y_test = []\n",
    "    train_count = 0\n",
    "    test_count = 0\n",
    "    for i in range(len(data)):\n",
    "        if random.random() < test_ratio:\n",
    "            test_count += 1\n",
    "            x_test.append(data[i])\n",
    "            y_test.append(label[i])\n",
    "        else:\n",
    "            train_count += 1\n",
    "            x_traintest.append((data[i],label[i]))\n",
    "            \n",
    "    return x_traintest, x_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finally, the bottom two functions implement the euclidian distance engine we built to determine the closest neighbors for each point in the testing set. \n",
    "\n",
    "The getNeighbors() function below takes our reference bank of training data (x_traintest) and determines what points are closest neighbors to an unknown data point (testInstance) from our testing dataset. The similarity input determines what operator to use to determine similarity (in this case, we use euclid()). Lastly, k is the number of neighbors an item has. This number **MUST** be odd as this prevents a bimodal similarity sample (equal number of different neighbors)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For each record in the training dataset, this determines a euclidian score\n",
    "# These scores are sorted, and the labels  of the most similar k values\n",
    "# Are returned (e.g. (5, Benign), (13.5, Malignant), etc.)\n",
    "\n",
    "def getNeighbors(data,testInstance,similarity,k):\n",
    "    neighbor = []\n",
    "    for i in range(len(data)):\n",
    "        neighbor.append(((similarity(data[i][0],testInstance)),data[i][1]))\n",
    "    \n",
    "    neighbor.sort(key=lambda tup: tup[0]) \n",
    "    \n",
    "    neighbors = pd.DataFrame()\n",
    "    neighbors['euclid'] = [x[0] for x in neighbor]\n",
    "    neighbors['label'] = [x[1] for x in neighbor]\n",
    "    \n",
    "    return neighbors['label'][:k].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the function above has to be called for every testing data point, the get_results function is used to iterate through all data points in the testing set instead of just one. The inputs of this function are fed into the getNeighbors function, and a raw resultlist of predictions is given (e.g. benign, malignant, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_results(x_traintest,x_test,k):\n",
    "    res_list = []\n",
    "    label = [x[1] for x in x_data]\n",
    "    for i in range(len(x_test)):\n",
    "        kNeighbor = getNeighbors(x_traintest, x_test[i],euclid,k)\n",
    "        res_list.append(mode(kNeighbor))\n",
    "    return res_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With our analysis now finished, we need to write functions that will let us view the model's results and performance "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The view_results() function returns a dataframe with three columns: The actual result for a person's cancer diagnosis, the predicted result, and whether or not the prediction was correct (True or False). This makes it easy for us to see what the program actually ran."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def view_results(actual,predicted):\n",
    "    result = pd.DataFrame()\n",
    "    for i in range(len(actual)):\n",
    "        actual[i] = dict[actual[i]]\n",
    "        predicted[i] = dict[predicted[i]]\n",
    "    result['ACTUAL'] = actual\n",
    "    result['PREDICTED'] = predicted\n",
    "    result['CORRECT?'] = [actual[i] == predicted[i] for i in range(len(actual))]\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moreover, we can see how accurate we are using the get_accuracy() function. This will tell us our accuracy as a percent, the raw number of cases we got correct, and the raw number of cases we got incorrect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_accuracy(actual, predicted):\n",
    "    count = 0\n",
    "    for i in range(len(actual)):\n",
    "        if actual[i] == predicted[i]:\n",
    "            count += 1\n",
    "    num_correct = count\n",
    "    num_incorrect = len(actual) - count\n",
    "    return (\"Accuracy: \" + str(count / len(actual)*100) + \" percent\" + '\\n' + \n",
    "           \"Number correct: \" + str(num_correct) + '\\n' + \n",
    "           \"Number incorrect: \" + str(num_incorrect))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## By calling the functions below, we can view our results and see how good our model is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       ACTUAL  PREDICTED CORRECT?\n",
      "0      benign     benign     True\n",
      "1      benign  malignant    False\n",
      "2      benign     benign     True\n",
      "3      benign     benign     True\n",
      "4      benign  malignant    False\n",
      "5      benign     benign     True\n",
      "6      benign     benign     True\n",
      "7   malignant  malignant     True\n",
      "8   malignant  malignant     True\n",
      "9   malignant  malignant     True\n",
      "10     benign     benign     True\n",
      "11     benign     benign     True\n",
      "12     benign     benign     True\n",
      "13     benign     benign     True\n",
      "14     benign     benign     True\n",
      "15     benign     benign     True\n",
      "16     benign     benign     True\n",
      "17     benign     benign     True\n",
      "18  malignant  malignant     True\n",
      "19  malignant  malignant     True\n",
      "\n",
      "Accuracy: 97.98657718120806 percent\n",
      "Number correct: 146\n",
      "Number incorrect: 3\n"
     ]
    }
   ],
   "source": [
    "#Makes testing data sample 20% of the entire dataset. This can be adjusted.\n",
    "#For the purposes of this model, this is the training step.\n",
    "x_data, x_test, y_test = train_test_split(data,label,0.2)\n",
    "\n",
    "#This tests the model and returns a list of results\n",
    "predicted_results = get_results(x_data,x_test,5)\n",
    "\n",
    "#Organizing our results so we can see 20 of our test cases\n",
    "viewed_results = view_results(y_test,predicted_results)\n",
    "viewed_results = viewed_results[:20]\n",
    "\n",
    "#This allows us to see the results\n",
    "print(viewed_results)\n",
    "print()\n",
    "print(get_accuracy(y_test,predicted_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
